{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab8-PartA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW-b-aWz472C"
      },
      "source": [
        "**Lab 8**\n",
        "\n",
        "Name: \n",
        "Date: \n",
        "\n",
        "**As you work through the code below, respond to all in-line comments and questions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjAME6fgMRo1"
      },
      "source": [
        "# Autoencoder\n",
        "\n",
        "First, let's again build a simple autoencoder for the MNIST data.  This lab is loosely modeled after [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKAFxQ0FSqFR"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load in the MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
        "\n",
        "N = int(.8 * train_X.shape[0])\n",
        "val_X = train_X[N:]/ 255\n",
        "val_Y = train_Y[N:]\n",
        "train_X = train_X[:N] / 255\n",
        "train_Y = train_Y[:N]\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, Input, Conv2D, MaxPooling2D, Reshape, Conv2DTranspose, UpSampling2D, GlobalMaxPooling2D\n",
        "from keras import regularizers\n",
        "\n",
        "encoder_input = Input(shape=(28, 28, 1), name=\"original_img\")\n",
        "x = Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
        "x = Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = MaxPooling2D(3)(x)\n",
        "x = Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = Conv2D(16, 3, activation=\"relu\")(x)\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "encoder_output = Dense(10, activation='relu')(x)\n",
        "\n",
        "encoder = Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "#encoder.summary()\n",
        "\n",
        "decoder_input = Input(shape=(10,), name=\"encoded_img\")\n",
        "x = Dense(16, activation='relu')(decoder_input)\n",
        "x = Reshape((4, 4, 1))(x)\n",
        "x = Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "x = Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
        "x = UpSampling2D(3)(x)\n",
        "x = Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "decoder_output = Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
        "\n",
        "decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "#decoder.summary()\n",
        "\n",
        "autoencoder_input = Input(shape=(28, 28, 1), name=\"img\")\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
        "\n",
        "autoencoder.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
        "autoencoder.fit(train_X, train_X,\n",
        "                epochs=25,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(val_X, val_X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIzTeBH9GaKg"
      },
      "source": [
        "Let's look at a few images, their codes and their reconstructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-WQh-3QGjRn"
      },
      "source": [
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "np.random.shuffle(val_X)\n",
        "\n",
        "sample = val_X[:3,:]\n",
        "\n",
        "print(sample.shape, type(sample))\n",
        "\n",
        "\n",
        "plt.imshow(sample[1,:].reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "x = encoder.predict(sample)\n",
        "print(x)\n",
        "reconstructions = autoencoder.predict(sample)\n",
        "\n",
        "print(reconstructions.shape, type(reconstructions))\n",
        "\n",
        "\n",
        "plt.imshow(reconstructions[1,:].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq7ThbHKSEy5"
      },
      "source": [
        "# Generate from the Autoencoder\n",
        "\n",
        "Use the autoencoder to generate some data.  How good is your generated data?  How might you improve the quality of your generated data?"
      ]
    }
  ]
}