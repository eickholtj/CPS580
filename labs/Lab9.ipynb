{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW-b-aWz472C"
      },
      "source": [
        "**Lab 9**\n",
        "\n",
        "Name: \n",
        "Date: \n",
        "\n",
        "**As you work through the code below, respond to all in-line comments and questions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjAME6fgMRo1"
      },
      "source": [
        "# Autoencoder\n",
        "\n",
        "First, let's try building a simple autoencoder for the MNIST data.  This lab is loosely modeled after [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bie6oJXBMUG"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load in the MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
        "\n",
        "N = int(.8 * train_X.shape[0])\n",
        "val_X = train_X[N:].reshape(-1,784) / 255\n",
        "val_Y = train_Y[N:]\n",
        "train_X = train_X[:N].reshape(-1,784) / 255\n",
        "train_Y = train_Y[:N]\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, Input\n",
        "from keras import regularizers\n",
        "\n",
        "print(train_X.shape)\n",
        "\n",
        "input_img = Input(shape=(784,))\n",
        "# Add a Dense layer with a L1 activity regularizer\n",
        "encoded = Dense(64, activation='relu')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(train_X, train_X,\n",
        "                epochs=25,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(val_X, val_X))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d9hJm3iOUhv"
      },
      "source": [
        "Now let's look at the enconding and reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A_OGszlEhBI"
      },
      "source": [
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "reconstructions = autoencoder.predict(val_X)\n",
        "encodings = encoder.predict(val_X)\n",
        "\n",
        "idx = 0\n",
        "\n",
        "print(\"Encoded representation\")\n",
        "print(encodings[idx,:])\n",
        "\n",
        "print(\"Original image\")\n",
        "image = val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Reconstruction\")\n",
        "image = reconstructions[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1YNM1F3OsC7"
      },
      "source": [
        "Go back and try to enforce a sparse encoding.  You may need to try to change the node type or number of nodes in the middle layer.  \n",
        "\n",
        ">  *encoded = Dense(64, activation='relu',*\n",
        "                *activity_regularizer=regularizers.l1(10e-5))(input_img)*\n",
        "\n",
        "**1. What was the architecture of the model that you used for your sparse encoder?  How well do you think it performs?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddJAKWD1Sf0a"
      },
      "source": [
        "# Denoising Autoencoder\n",
        "\n",
        "Let's add some noise to the input and see if we can do some reconstructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUodOTDvQJC_"
      },
      "source": [
        "# Reload the data but add some noise\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load in the MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
        "\n",
        "N = int(.8 * train_X.shape[0])\n",
        "val_X = train_X[N:].reshape(-1,784) / 255.\n",
        "val_Y = train_Y[N:]\n",
        "train_X = train_X[:N].reshape(-1,784) / 255.\n",
        "train_Y = train_Y[:N]\n",
        "\n",
        "noisy_train_X = train_X + 0.3 * np.random.normal(size=train_X.shape)\n",
        "noisy_val_X = val_X + 0.3 * np.random.normal(loc=0.0, scale=1.0, size=val_X.shape)\n",
        "\n",
        "noisy_train_X = np.clip(noisy_train_X, 0., 1.)\n",
        "noisy_val_X = np.clip(noisy_val_X, 0., 1.)\n",
        "\n",
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = 0\n",
        "\n",
        "print(\"Original image\")\n",
        "image = val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Noisy image\")\n",
        "image = noisy_val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA2BMrpXVV0W"
      },
      "source": [
        "Build, evaluate and visualize a denoising autoencoder.  \n",
        "\n",
        "**2. How well does it do removing noise?  How well does it do reconstructing clean images?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OSX6_6gTyZ1"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, Input\n",
        "from keras import regularizers\n",
        "\n",
        "# Build, evaluate and visualize a denoising autoencoder\n",
        "\n",
        "#input_img = Input(shape=(784,))\n",
        "\n",
        "# ...\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YeYisIFUYc2"
      },
      "source": [
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "reconstructions = autoencoder.predict(val_X)\n",
        "#reconstructions = autoencoder.predict(noisy_val_X)\n",
        "\n",
        "idx = 89\n",
        "\n",
        "print(\"Original image\")\n",
        "image = val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Noisy image\")\n",
        "image = noisy_val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Reconstruction\")\n",
        "image = reconstructions[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6xDmpgHV9zR"
      },
      "source": [
        "# Spy Autoencoder\n",
        "\n",
        "Consider the task of filling in a portion of the image that has been covered up.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4eLrtC4XJcY"
      },
      "source": [
        "# Reload the data but add some noise\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Load in the MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
        "\n",
        "patch_size = 8\n",
        "\n",
        "N = int(.8 * train_X.shape[0])\n",
        "val_X = train_X[N:] / 255.\n",
        "val_Y = train_Y[N:]\n",
        "train_X = train_X[:N] / 255.\n",
        "train_Y = train_Y[:N]\n",
        "\n",
        "blotted_train_X = np.copy(train_X)\n",
        "blotted_val_X = np.copy(val_X)\n",
        "\n",
        "for digit in blotted_train_X:\n",
        "\n",
        "    x_offset = random.randint(10, 18)\n",
        "    y_offset = random.randint(10, 18)\n",
        "\n",
        "    digit[x_offset:x_offset + patch_size, y_offset:y_offset + patch_size] = 1.\n",
        "\n",
        "for digit in blotted_val_X:\n",
        "\n",
        "    x_offset = random.randint(8, 20)\n",
        "    y_offset = random.randint(8, 20)\n",
        "\n",
        "    digit[x_offset:x_offset + patch_size, y_offset:y_offset + patch_size] = 1.\n",
        "\n",
        "idx = 0\n",
        "\n",
        "blotted_train_X = blotted_train_X.reshape((-1, 784))\n",
        "blotted_val_X = blotted_val_X.reshape((-1, 784))\n",
        "train_X = train_X.reshape((-1, 784))\n",
        "val_X = val_X.reshape((-1, 784))\n",
        "\n",
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Original image\")\n",
        "image = val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Blotted image\")\n",
        "image = blotted_val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXKET7GGcPKc"
      },
      "source": [
        "Build, evaluate and visualize an autoencoder to spy behind the plotted portion of the image.\n",
        "\n",
        "**3. Does it make any difference if the square is filled with black instead of white?  How well can the model reconstruct the missing region.  Try with larger and smaller missing portions.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_dblYePcbKL"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, Input\n",
        "from keras import regularizers\n",
        "\n",
        "# Build, evaluate and visualize a denoising autoencoder\n",
        "\n",
        "#input_img = Input(shape=(784,))\n",
        "\n",
        "# ...\n",
        "\n",
        "#autoencoder.fit(blotted_train_X, train_X,\n",
        "                epochs=25,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(blotted_val_X, val_X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP-SdioVePi9"
      },
      "source": [
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "reconstructions = autoencoder.predict(blotted_val_X)\n",
        "\n",
        "idx = 89\n",
        "\n",
        "print(\"Original image\")\n",
        "image = val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Noisy image\")\n",
        "image = blotted_val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Reconstruction\")\n",
        "image = reconstructions[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0yQCpfte9Hv"
      },
      "source": [
        "# Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hifWX9NKieOo"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load in the MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
        "\n",
        "N = int(.8 * train_X.shape[0])\n",
        "val_X = train_X[N:].reshape((-1,28,28,1)) / 255.\n",
        "val_Y = train_Y[N:]\n",
        "train_X = train_X[:N].reshape((-1,28,28,1)) / 255.\n",
        "train_Y = train_Y[:N]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM3pLHWTfJJ8"
      },
      "source": [
        "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(train_X, train_X,\n",
        "                epochs=25,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(val_X, val_X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcJ2r3Rmj80t"
      },
      "source": [
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "reconstructions = autoencoder.predict(val_X)\n",
        "\n",
        "idx = 0\n",
        "\n",
        "print(\"Original image\")\n",
        "image = val_X[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Reconstruction\")\n",
        "image = reconstructions[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E7bjBi_fKFG"
      },
      "source": [
        "# Derotational Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04chYtzUT8X5"
      },
      "source": [
        "Let's use the convolutional autoencoder to \"undo\" rotations and shifts.  \n",
        "\n",
        "**4. How well does the detransformational autoencoder do?  Do you think a non-convolutional autoencoder would be better suited for this task?  Why or why not?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASpdoYOQfRv_"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#datagen = ImageDataGenerator(\n",
        "#        rotation_range=40,\n",
        "#        width_shift_range=0.2,\n",
        "#        height_shift_range=0.2,\n",
        "#        shear_range=0.2,\n",
        "#        zoom_range=0.2,\n",
        "#        horizontal_flip=True,\n",
        "#        fill_mode='nearest')\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=30)\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "#input_img = Input(shape=(28, 28))\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(datagen.flow(train_X, train_X, batch_size=32), steps_per_epoch=len(train_X) / 32, \n",
        "          epochs=10, validation_data=datagen.flow(val_X, val_X, batch_size=32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrKSxx_KhKla"
      },
      "source": [
        "for transformed_X_batch, original_X_batch in datagen.flow(val_X, val_X, batch_size=32):\n",
        "\n",
        "    loss_and_metrics = autoencoder.evaluate(transformed_X_batch, transformed_X_batch)\n",
        "    print(loss_and_metrics)\n",
        "\n",
        "    reconstructions = autoencoder.predict(transformed_X_batch)\n",
        "\n",
        "    break\n",
        "\n",
        "\n",
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = 0\n",
        "\n",
        "print(\"Original image\")\n",
        "image = original_X_batch[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Transfomred image\")\n",
        "image = transformed_X_batch[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Reconstruction\")\n",
        "image = reconstructions[idx,:]\n",
        "plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx-wzaSxVmaM"
      },
      "source": [
        "**5. Try some other transformations or combinations of transformations.  What did you try and how well did they do?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjnsnaJoWDfM"
      },
      "source": [
        "**Submission:** Submit this notebook and a PDF of its generated output via Blackboard by the end of the day.  Submit the files individually."
      ]
    }
  ]
}