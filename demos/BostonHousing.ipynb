{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BostonHousing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHmGiR9l2WRo",
        "colab_type": "text"
      },
      "source": [
        "## Boston Housing ##\n",
        "\n",
        "Let's build a regressor and train it using a k-fold cross-validation approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFAH84tg7HN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n",
        "\n",
        "# Let's take a look at the data\n",
        "\n",
        "print(train_data.shape, train_targets.shape)\n",
        "print(train_data[0,:], train_targets[0])\n",
        "\n",
        "train_X = train_data\n",
        "train_Y = train_targets\n",
        "\n",
        "test_X = test_data\n",
        "test_Y = test_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUYxiEp6GZMD",
        "colab_type": "text"
      },
      "source": [
        "Just for grins, we go ahead and build a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRgnRJPLGjvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(train_data.shape[1],)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model.fit(train_X, train_Y, epochs = 10, batch_size=32, validation_split=0.2)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR2WmBaEJkmm",
        "colab_type": "text"
      },
      "source": [
        "One thing we can do is normalize the input.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l40Ibt-WJymW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_X.mean(axis=0)\n",
        "train_X -= mean\n",
        "std = train_X.std(axis=0)\n",
        "train_X /= std\n",
        "\n",
        "test_X -= mean\n",
        "test_X /= std\n",
        "\n",
        "model.fit(train_X, train_Y, epochs = 25, batch_size=32, validation_split=0.2)\n",
        "\n",
        "model.evaluate(test_X, test_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2pcpr5HK2nR",
        "colab_type": "text"
      },
      "source": [
        "Now we will train using k fold-cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPMH3v6pL2Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    # Because we will need to instantiate\n",
        "    # the same model multiple times,\n",
        "    # we use a function to construct it.\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(train_data.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# You could combine training and test datasets here ...\n",
        "\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 2\n",
        "all_val_maes = []\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # Prepare the validation data: data from partition # k\n",
        "    val_X = train_X[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_Y = train_Y[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_X = np.concatenate(\n",
        "        [train_X[:i * num_val_samples],\n",
        "         train_X[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_Y = np.concatenate(\n",
        "        [train_Y[:i * num_val_samples],\n",
        "         train_Y[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    history = model.fit(partial_train_X, partial_train_Y,\n",
        "                        validation_data=(val_X, val_Y),\n",
        "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
        "    # Evaluate the model on the validation data\n",
        "    val_mse, val_mae = model.evaluate(val_X, val_Y, verbose=0)\n",
        "    all_val_maes.append(val_mae)\n",
        "\n",
        "    all_preds.append(model.predict(val_X).flatten().tolist())\n",
        "    all_targets.append(val_Y.flatten().tolist())\n",
        "    \n",
        "print(\"Average mae on validation accross folds: \", sum([i / len(all_val_maes) for i in all_val_maes]))\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "all_preds = flatten(all_preds)\n",
        "all_targets = flatten(all_targets)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print(\"mae on validation set: \", mean_absolute_error(all_targets, all_preds))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}