{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras, MNIST and GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHmGiR9l2WRo",
        "colab_type": "text"
      },
      "source": [
        "## Keras and MNIST ##\n",
        "\n",
        "Let's have another look at the MNIST dataset and this time build some classifiers using Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFAH84tg7HN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import random\n",
        "\n",
        "# Load in the MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
        "\n",
        "N = int(.8 * train_X.shape[0])\n",
        "val_X = train_X[N:]\n",
        "val_Y = train_Y[N:]\n",
        "train_X = train_X[:N]\n",
        "train_Y = train_Y[:N]\n",
        "\n",
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for image, label in ([(train_X[idx,:], train_Y[idx]) for idx in np.arange(train_X.shape[0])[:3]]):\n",
        "    print(type(image), type(label))\n",
        "    print('Label:', label)\n",
        "    print('Digit in the image')\n",
        "    plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0dg3JTTDD21",
        "colab_type": "text"
      },
      "source": [
        "We still have some work to do.  Let's limit ourselves to 0's and 8's.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymhRMlXzDazq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ze_train_X = np.concatenate((train_X[train_Y == 0,:], train_X[train_Y == 8,:]), axis = 0)\n",
        "ze_train_Y = np.concatenate((train_Y[train_Y == 0], train_Y[train_Y == 8]), axis = 0)\n",
        "\n",
        "ze_test_X = np.concatenate((test_X[test_Y == 0,:], test_X[test_Y == 8,:]), axis = 0)\n",
        "ze_test_Y = np.concatenate((test_Y[test_Y == 0], test_Y[test_Y == 8]), axis = 0)\n",
        "\n",
        "# And set all 8's to 1's for the binary classification task (i.e., predict 0 or 1)\n",
        "ze_train_Y[ze_train_Y == 8] = 1\n",
        "ze_test_Y[ze_test_Y == 8] = 1\n",
        "\n",
        "# Let's shuffle the order of the training data\n",
        "ze_train_indices = np.arange(ze_train_X.shape[0])\n",
        "np.random.shuffle(ze_train_indices)\n",
        "\n",
        "ze_train_X = ze_train_X[ze_train_indices,:]\n",
        "ze_train_Y = ze_train_Y[ze_train_indices]\n",
        "\n",
        "# We'll take another look at the selected training data\n",
        "for image, label in ([(ze_train_X[idx,:], ze_train_Y[idx]) for idx in np.arange(ze_train_X.shape[0])[:5]]):\n",
        "    print(type(image), type(label))\n",
        "    print('Label:', label)\n",
        "    print('Digit in the image')\n",
        "    plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "print(np.sum(ze_train_Y == 0))\n",
        "print(np.sum(ze_train_Y == 1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zxMHlM5IY9i",
        "colab_type": "text"
      },
      "source": [
        "Now let's train up a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "503AYQMMXSYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape and normalize input\n",
        "ze_train_X = ze_train_X.reshape((ze_train_X.shape[0], -1)) /255.\n",
        "ze_test_X = ze_test_X.reshape((ze_test_X.shape[0], -1)) / 255.\n",
        "\n",
        "print(ze_train_X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsKPBmNiPKyH",
        "colab_type": "text"
      },
      "source": [
        "We will build up a sequential model, layer by layer.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLhulPvsYMJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=64, activation='sigmoid', input_dim=28*28))\n",
        "#model.add(Dense(units=250, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Specify the loss, optimizer and any additional metrics to follow\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the training data, set epochs and batch size\n",
        "model.fit(ze_train_X, ze_train_Y, epochs=10, batch_size=32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa454BhLU00M",
        "colab_type": "text"
      },
      "source": [
        "And then apply the model to the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yftvtg2qU3VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_and_metrics = model.evaluate(ze_test_X, ze_test_Y)\n",
        "print(loss_and_metrics)\n",
        "\n",
        "# Sometimes it is helpful to look at the raw predictions.  If the model is\n",
        "# learning something, you should see some patterns.  All 0's or 1's or some fixed\n",
        "# value are signs something is wrong.\n",
        "raw_preds = model.predict(ze_test_X)\n",
        "print(raw_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUkSm_8sYjGH",
        "colab_type": "text"
      },
      "source": [
        "Do you notice a dip in performance between the training data and the test data?  What do you notice about raw outputs?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6owlm_QTL6",
        "colab_type": "text"
      },
      "source": [
        "Consider these questions.  When we adjust the size of the model, should we consider the performance of the adjusted model on the training data or test data?  Is there any reason why might want to evaluate the model on a dataset other than the test or training dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB33ZzbOYyW_",
        "colab_type": "text"
      },
      "source": [
        "How do you know if you are using at GPU?  Once we get to more involved examples, you will be able to tell.  You don't have access to a GPU by default but can [select a GPU enabled run time](https://colab.research.google.com/notebooks/gpu.ipynb).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTuJktveYxeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO1OvSiubTrN",
        "colab_type": "text"
      },
      "source": [
        "How robust do you think the network that we trained up will be for novel data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbwu-63hbb3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    vertical_flip=True)\n",
        "\n",
        "\n",
        "for X_batch, Y_batch in datagen.flow(ze_test_X.reshape((-1, 28,28, 1)), ze_test_Y, batch_size=5):\n",
        "    for image, label in ([(X_batch[idx,:], Y_batch[idx]) for idx in np.arange(X_batch.shape[0])]):\n",
        "        print(type(image), type(label))\n",
        "        print('Label:', label)\n",
        "        print('Digit in the image')\n",
        "        plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "        plt.show()\n",
        "\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U08VHgSnhWzD",
        "colab_type": "text"
      },
      "source": [
        "How do you think that our model will perform on this augmented data?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrKSxx_KhKla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for X_batch, Y_batch in datagen.flow(ze_test_X.reshape((-1, 28,28, 1)), ze_test_Y, batch_size=32):\n",
        "\n",
        "    X_batch = X_batch.reshape((-1,28*28))\n",
        "\n",
        "    loss_and_metrics = model.evaluate(X_batch, Y_batch)\n",
        "    print(loss_and_metrics)\n",
        "\n",
        "    raw_preds = model.predict(X_batch)\n",
        "\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-y_lHW8QOEu",
        "colab_type": "text"
      },
      "source": [
        "Ouch!"
      ]
    }
  ]
}